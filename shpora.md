шпаргалка по основам алгоритмов и структур данных

1. базовое понятие алгоритма  
алгоритм — конечная последовательность однозначных инструкций для решения задачи  
свойства: дискретность, детерминированность, конечность, массовость, результативность  
неформальное определение: алгоритм — это понятное и точное предписание, определяющее последовательность действий над исходными данными для получения результата за конечное число шагов  
определение кнута включает пять важных черт: конечность, определенность, наличие входных и выходных данных, эффективность  
математическое определение: алгоритм — это вычислимая функция, реализуемая некоторой формальной моделью вычислений  
вычислительная сложность отражает количество элементарных операций, необходимых для выполнения алгоритма  
описательная сложность — это длина текста или кода, описывающего алгоритм  
главный параметр сложности — размер входных данных, обычно обозначаемый как n

2. математические основы данных  
системы счисления: двоичная (основание 2), десятичная (10), шестнадцатеричная (16)  
двоичная система — основная для хранения и обработки данных в компьютерах  
шестнадцатеричная система используется для компактной записи адресов памяти и двоичных дампов  
десятичная система основна для ввода/вывода, но требует преобразования, что вносит погрешности в дробные числа  
преобразования между системами выполняются через деление на основание или группировку битов  
проверка корректности записи числа: каждая цифра должна быть строго меньше основания системы  
побитовые операции работают на уровне отдельных битов  
and возвращает 1 только если оба бита равны 1  
or возвращает 1, если хотя бы один бит равен 1  
xor возвращает 1, если биты различны  
not инвертирует каждый бит  
применяются для работы с флагами, масками, шифрованием и оптимизациями

3. представление чисел  
числа с плавающей запятой хранятся в формате ieee 754, который включает знак, экспоненту и мантиссу  
число хранится в виде ±m × 2^e, где m — мантисса, e — экспонента  
бит знака (s) определяет знак числа (0 — плюс, 1 — минус)  
экспонента хранится со смещением (bias), чтобы избежать знакового бита  
мантисса хранит значащие цифры с использованием "скрытой единицы", что увеличивает точность на 1 бит  
форматы: float32 (single) — 8 бит экспоненты, 23 бита мантиссы, точность ~7 знаков  
float64 (double) — 11 бит экспоненты, 52 бита мантиссы, точность ~16 знаков  
bfloat16 оптимизирован для ии, жертвуя точностью мантиссы ради диапазона экспоненты  
машинная точность ε — это наименьшее положительное число, такое что 1 + ε ≠ 1 в арифметике компьютера  
обычно ε ≈ 2⁻⁵² для double в ieee 754  
вычисляется итеративным делением пополам, пока 1 + ε/2 перестает отличаться от 1  
быстрое возведение в степень использует рекурсивное разложение: aⁿ = (aⁿ/²)² при чётном n и a·aⁿ⁻¹ при нечётном  
сложность этого метода — o(log n)  
алгоритм евклида находит наибольший общий делитель двух чисел с помощью последовательного взятия остатка  
его время работы пропорционально логарифму меньшего из чисел  
перевод в римские числа осуществляется заменой арабских цифр на соответствующие символы по убыванию значений

4. типы данных и операции  
элементарные типы: целые, вещественные, логические, символьные  
в python элементарные типы включают int, float, complex, bool  
производные типы включают массивы, структуры, перечисления и указатели  
в python производные типы: list, tuple, dict, set, frozenset  
массив — упорядоченный набор элементов одного типа с доступом по индексу  
базовые операции: линейный поиск, нахождение минимума и максимума, вычисление префиксных сумм  
поиск максимума и минимума выполняется за один проход по массиву с o(n)  
префиксные суммы позволяют быстро находить сумму на любом подотрезке за o(1) после o(n) предподсчёта  
динамический массив автоматически увеличивает свой размер при добавлении новых элементов, обычно вдвое  
линейный поиск последовательно сравнивает искомый ключ с каждым элементом массива до нахождения совпадения  
бинарный поиск применяется только для отсортированных массивов и имеет сложность o(log n)

5. комплексные числа  
алгебраическая форма записи: a + bi, где i² = −1  
комплексные числа позволяют извлекать корень из отрицательных чисел и решать уравнения без решения в действительных числах  
показательная форма: r·e^(iφ), где r — модуль, φ — аргумент (угол)  
арифметические операции: сложение и вычитание покомпонентны, умножение и деление удобнее в показательной форме  
сложение/вычитание: (a + bi) ± (c + di) = (a ± c) + (b ± d)i  
умножение выполняется с раскрытием скобок с учетом i² = −1  
деление производится умножением числителя и знаменателя на сопряженное знаменателю число  
модуль комплексного числа |z| = √(a² + b²)  
сортировка комплексных чисел возможна по модулю или по аргументу, в зависимости от задачи

6. асимптотический анализ  
асимптотические обозначения описывают поведение функций при стремлении аргумента к бесконечности  
o(f(n)) задаёт верхнюю границу: t(n) ≤ c·f(n) для достаточно больших n  
Ω(f(n)) — нижняя граница: t(n) ≥ c·f(n)  
Θ(f(n)) означает, что функция ограничена сверху и снизу одним порядком роста  
классификация сложностей: o(1) — константная, o(log n) — логарифмическая, o(n) — линейная, o(n log n) — линеарифметическая, o(n²) — квадратичная, o(2ⁿ) — экспоненциальная  
сравнение скоростей роста: константы < логарифмы < линейные < n log n < квадратичные < экспоненциальные  
ram-модель (random access machine) предполагает, что любая базовая операция (чтение, запись, арифметика) выполняется за единичное время  
эта модель используется для теоретического анализа алгоритмов без учёта особенностей реального железа  
главный параметр при анализе сложности — размер входных данных n  
временная сложность измеряет время выполнения, пространственная — дополнительную память

7. амортизационный анализ  
амортизационный анализ оценивает среднюю стоимость операции в последовательности, даже если отдельные операции могут быть дорогими  
метод усреднения (агрегирования): вычисляется суммарная стоимость всей последовательности операций t(n) в худшем случае, затем делится на количество операций n  
в динамическом массиве суммарная стоимость n вставок составляет o(n), значит амортизированное время одной вставки — o(1)  
метод предоплаты (бухгалтерский): операциям назначается фиксированная "учетная стоимость", которая может отличаться от реальной  
для дешевых операций устанавливается стоимость выше реальной, разница сохраняется как "кредит" на счету структуры данных  
дорогие операции оплачиваются из накопленного кредита  
теорема: если баланс счета всегда неотрицательный, то назначенные стоимости являются корректными амортизационными  
метод потенциалов: вводится функция потенциала Φ, и амортизированная стоимость = реальная стоимость + изменение потенциала  
пример — динамический массив: при переполнении происходит копирование, но амортизированная стоимость push остается o(1)  
очередь на двух стеках: enqueue — в один стек, dequeue — из другого; при опустошении второго стека перекидываем всё из первого, что дает амортизированное o(1)

8. квадратичные сортировки  
пузырьковая сортировка многократно проходит по массиву, меняя соседние элементы, если они стоят в неправильном порядке  
сортировка выбором находит минимальный элемент и ставит его в начало, затем повторяет для оставшейся части  
сортировка вставками поочередно вставляет элементы в уже отсортированную часть массива  
все три имеют временную сложность o(n²) в худшем случае  
пузырьковая сортировка — самый медленный способ сортировки, так как большие элементы уходят в конец массива  
сортировка выбором имеет минимальное количество перестановок o(n), но квадратичное количество сравнений  
сортировка вставками эффективна на почти отсортированных данных и малых массивах, имеет o(n) в лучшем случае

9. рекурсивные сортировки  
сортировка слиянием делит массив пополам, рекурсивно сортирует части и сливает их в отсортированный массив  
она устойчива, то есть не меняет порядок равных элементов, и всегда работает за o(n log n)  
принцип работы: массив рекурсивно делится пополам, пока не останутся части из одного элемента, затем эти части сливаются в более крупные отсортированные блоки  
временная сложность всегда o(n log n) для лучшего, среднего и худшего случаев  
пространственная сложность o(n) — требует дополнительного пространства для временного хранения сливаемых частей  
сортировка подсчетом применима только к целым числам из ограниченного диапазона [0, k]  
она создает массив счетчиков размером k+1, затем восстанавливает порядок элементов  
ее сложность — o(n + k), что линейно при малом k  
применяется как подпрограмма в других алгоритмах, например в radix sort

10. быстрая сортировка (quicksort)  
алгоритм выбирает опорный элемент (pivot), разделяет массив на элементы меньше и не меньше pivot, затем рекурсивно сортирует обе части  
в среднем случае, при случайном выборе pivot, сложность составляет o(n log n)  
доказательство сложности o(n log n): глубина рекурсии log n при сбалансированном разделении, работа на каждом уровне o(n)  
худший случай (например, когда pivot всегда минимальный или максимальный) имеет сложность o(n²)  
на практике quicksort часто быстрее других сортировок благодаря хорошей локальности данных и низкой константе  
существуют оптимизации: выбор медианы из трех элементов, переход на сортировку вставками для малых подмассивов

11. теоретические пределы сортировок  
для любого алгоритма сортировки, основанного только на сравнениях, существует нижняя граница Ω(n log n)  
это следует из того, что дерево решений должно иметь не менее n! листьев, а его высота не меньше log₂(n!)  
таким образом, merge sort и heap sort асимптотически оптимальны среди comparison-based алгоритмов  
сортировки без сравнений (counting sort, radix sort) могут достигать линейной сложности o(n), но имеют ограничения по диапазону значений

12. рекурсия  
рекурсивная функция вызывает саму себя с измененными аргументами  
обязательные условия корректной рекурсии: наличие базового случая и продвижение к нему на каждом шаге  
стек вызовов хранит контекст каждого активного вызова, включая локальные переменные и адрес возврата  
классические примеры: вычисление факториала, чисел фибоначчи, решение задачи о ханойских башнях  
числа фибоначчи можно вычислять разными способами: простой рекурсией (o(2^n)), итерацией (o(n)), мемоизацией (o(n)), матричным возведением в степень (o(log n))  
мемоизация — техника кэширования результатов подзадач для избежания повторных вычислений, особенно полезна в динамическом программировании  
быстрый алгоритм для фибоначчи использует матричное возведение в степень и работает за o(log n)

13. рекуррентные соотношения и мастер-теорема  
многие рекурсивные алгоритмы описываются рекуррентой вида t(n) = at(n/b) + f(n), где a ≥ 1, b > 1  
мастер-теорема дает готовые условия для определения асимптотики таких рекуррент без их полного решения  
случай 1: если f(n) = o(n^(log_b(a−ε)) для некоторого ε > 0, то t(n) = Θ(n^log_b(a))  
случай 2: если f(n) = Θ(n^log_b(a) · logᵏn), то t(n) = Θ(n^log_b(a) · logᵏ⁺¹n)  
случай 3: если f(n) = Ω(n^(log_b(a+ε))) для некоторого ε > 0 и af(n/b) ≤ cf(n) для некоторого c < 1 и достаточно больших n, то t(n) = Θ(f(n))  
пример для быстрой сортировки: при случайном выборе pivot, средняя сложность t(n) = 2t(n/2) + o(n) = o(n log n)  
пример для сортировки слиянием: a = 2, b = 2, f(n) = n → log_b a = 1, f(n) = Θ(n), значит t(n) = Θ(n log n)  
рекуррентное соотношение — это уравнение, выражающее элемент последовательности через предыдущие

14. линейные структуры данных  
односвязный список состоит из узлов, каждый из которых содержит данные и указатель на следующий узел  
основной узел (node) хранит данные (data) и ссылку на следующий узел (next_node)  
двусвязный список дополнительно хранит указатель на предыдущий узел, что позволяет двигаться в обе стороны  
основные операции в односвязном списке: добавление в начало (o(1)), добавление в конец (o(n)), поиск (o(n)), удаление (o(n))  
если хранить указатель tail (хвост), сложность добавления в конец становится o(1)  
списки гибче массивов по памяти, но хуже по локальности и произвольному доступу  
для удаления узла нужно найти предыдущий узел и перенаправить его ссылку на следующий за удаляемым

15. стек  
стек — структура данных с принципом lifo (последним пришел — первым ушел)  
основные операции: push (добавить наверх), pop (удалить верхний), peek (посмотреть верхний без удаления), isempty (проверить пустоту)  
реализуется на массиве (с указателем на вершину) или на связном списке  
часто используется для проверки корректности скобочных последовательностей, вычисления выражений в обратной польской записи  
для поддержки операции поиска минимума можно использовать вспомогательный стек, хранящий текущий минимум для каждой глубины основного стека  
при добавлении элемента в min_stack добавляется только если он меньше или равен текущему минимуму  
при удалении элемента из основного стека, если он равен вершине min_stack, то удаляется и из min_stack

16. очередь  
очередь работает по принципу fifo (первым пришел — первым ушел)  
операции: enqueue (добавить в конец), dequeue (извлечь из начала), front/peek (посмотреть первый без удаления), isempty  
реализации: циклический буфер — эффективная реализация на массиве с двумя указателями (head и tail)  
очередь на двух стеках: один стек для добавления (stack_in), второй для удаления (stack_out)  
когда stack_out пуст, все элементы из stack_in переносятся в stack_out, что инвертирует порядок и восстанавливает fifo  
амортизированная сложность операций enqueue и dequeue составляет o(1)  
двойной разворот (добавление в первый стек, перенос во второй) восстанавливает исходный порядок элементов

17. куча (бинарная)  
бинарная куча — полное бинарное дерево, в котором выполняется свойство кучи: значение родителя не больше (min-heap) или не меньше (max-heap) значений детей  
куча является специализированным деревом, которое является полным (заполняется строго сверху вниз и слева направо)  
хранится в массиве: для элемента с индексом i дети находятся на позициях 2i+1 и 2i+2, родитель — на (i−1)//2  
просеивание вверх (sift-up) используется после вставки, чтобы восстановить порядок  
просеивание вниз (sift-down) — после извлечения корня  
для поддержания свойств кучи используются процедуры sift-up (всплытие) и sift-down (погружение)  
доступ к минимуму в min-heap или максимуму в max-heap осуществляется за o(1)

18. операции на куче и ее применения  
вставка: добавляем в конец массива и просеиваем вверх за o(log n)  
извлечение экстремума: меняем корень с последним элементом, удаляем последний, просеиваем новый корень вниз за o(log n)  
построение кучи из массива за o(n) возможно с помощью просеивания вниз для всех внутренних узлов снизу вверх  
куча лежит в основе очереди с приоритетом и алгоритма пирамидальной сортировки (heapsort)  
heapsort строит max-heap, затем последовательно извлекает максимум и помещает его в конец массива  
сложность heapsort — o(n log n) во всех случаях, дополнительная память o(1)  
пример реализации кучи на python использует модуль heapq с методами heapify, heappush, heappop

19. более сложные структуры на основе кучи  
поиск k-го наименьшего элемента: можно использовать max-heap размера k, сохраняя в нем k самых маленьких элементов  
слияние k отсортированных массивов: в min-heap кладутся первые элементы всех массивов, затем извлекается минимум и добавляется следующий элемент из того же массива  
биномиальные кучи — более сложная структура, представляющая собой лес биномиальных деревьев  
биномиальное дерево b_k состоит из одного узла при k=0 или формируется присоединением одного дерева b_{k-1} к корню другого b_{k-1}  
в дереве b_k ровно 2^k узлов, высота равна k  
биномиальные кучи поддерживают эффективное слияние за o(log n), но редко используются на практике

20. теория графов: основы  
граф состоит из множества вершин и ребер между ними  
может быть ориентированным (рёбра имеют направление) или неориентированным  
степень вершины — число ребер, инцидентных ей; в орграфе различают входящую и исходящую степени  
лемма о рукопожатиях утверждает, что сумма степеней всех вершин равна удвоенному числу ребер  
граф можно хранить в виде матрицы смежности (удобно для плотных графов) или списков смежности (эффективно для разреженных)  
матрица смежности требует o(v²) памяти, списки смежности — o(v + e)  
вершины могут содержать дополнительную информацию (веса, метки), ребра тоже могут иметь веса

21. связность в графах  
компоненты связности — максимальные подграфы, в которых любые две вершины соединены путем  
в ориентированных графах различают слабую и сильную связность  
мост — ребро, удаление которого увеличивает число компонент связности  
точка сочленения — вершина, удаление которой нарушает связность  
алгоритмы поиска мостов и точек сочленения основаны на dfs с отслеживанием времени входа и low-link значений  
алгоритмы работают за o(v + e) с использованием dfs или bfs с дополнительными структурами данных

22. деревья  
дерево — связный ациклический неориентированный граф  
эквивалентные определения: n вершин и n−1 ребро, единственный простой путь между любой парой вершин, связный и без циклов  
между любыми двумя вершинами существует ровно один путь  
количество ребер всегда на единицу меньше количества вершин (|e| = |v|−1)  
у дерева всегда есть хотя бы одна "висячая" вершина (степень которой равна 1)  
остовное дерево графа — подграф, содержащий все вершины и являющийся деревом  
взвешенные графы могут иметь минимальное остовное дерево (mst), строящееся алгоритмами кrusкала или прима

23. эйлеровы пути и циклы  
эйлеров цикл проходит по каждому ребру ровно один раз и заканчивается в начальной вершине  
эйлеров путь делает то же самое, но начинается и заканчивается в разных вершинах  
в неориентированном графе эйлеров цикл существует тогда и только тогда, когда граф связен и все степени четны  
эйлеров путь существует, если граф связен и ровно две вершины имеют нечетную степень  
алгоритм hierholzer строит такой путь за линейное время, последовательно удаляя использованные ребра  
маршрут — последовательность вершин и ребер (ребра и вершины могут повторяться)  
путь — маршрут, в котором все ребра и вершины уникальны (кроме, возможно, начальной/конечной)  
цикл — путь, который начинается и заканчивается в одной и той же вершине

24. обход графов: bfs  
поиск в ширину использует очередь для обхода вершин по уровням от начальной  
гарантированно находит кратчайший путь в невзвешенном графе  
алгоритм помечает расстояния от стартовой вершины и предшественников для восстановления пути  
временная сложность — o(n + m), где n — число вершин, m — число ребер  
bfs подходит для поиска компонент связности, проверки двудольности графа  
при обходе помечаются посещенные вершины, чтобы избежать зацикливания

25. обход графов: dfs  
поиск в глубину исследует граф, углубляясь в одну ветвь до упора, затем возвращаясь назад  
реализуется рекурсивно или с явным стеком  
применяется для поиска компонент связности, обнаружения циклов, топологической сортировки и поиска сильно связных компонент  
топологическая сортировка возможна только в dag (ориентированном ациклическом графе) и строится по убыванию времени выхода из вершин в dfs  
dfs можно использовать для классификации ребер: древесные, обратные, прямые, поперечные  
временная сложность — o(n + m), где n — число вершин, m — число ребер  
при обнаружении обратного ребра в dfs можно заключить, что в графе есть цикл
